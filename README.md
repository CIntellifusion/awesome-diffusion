# awesome-diffusion





## Introduction

Models based on diffusion has shown fantastic performance on image generation and other tasks. Although each day comes several papers about diffusion, there are several major topics about it :applications , theory and engineering improvement, conditional generation. 



## Newest Survey Papers

| Year | Title                                                        | Venue | Paper                                   | Code |
| ---- | ------------------------------------------------------------ | ----- | --------------------------------------- | ---- |
| 2023 | Diffusion Models: A Comprehensive Survey of Methods and Applications | Arxiv | [Link](https://github.com/YangLing0818) | /    |

In this survey of diffusion models, more than 300 papers were surveyed, but only few months after it was published, another 300 papers has been produced,especially after [Controlnet](https://arxiv.org/abs/2210.09643) was released. 

## Papers

### applications 

mainly about 3d diffusion applications and cross-modality applications, which are both very popular topics nowadays. 

| Time     | Title                                                        | Venue     | Code                                                         |
| -------- | ------------------------------------------------------------ | --------- | ------------------------------------------------------------ |
| 20220407 | [Video Diffusion Models](https://arxiv.org/pdf/2204.03458v2.pdf) |           | [link](https://paperswithcode.com/paper/video-diffusion-models#code) |
| 20221222 | [Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation](https://paperswithcode.com/paper/tune-a-video-one-shot-tuning-of-image) | arxiv     | [link]()                                                     |
| 2023     | [MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation](https://paperswithcode.com/paper/mm-diffusion-learning-multi-modal-diffusion) | CVPR      | [link](https://paperswithcode.com/paper/mm-diffusion-learning-multi-modal-diffusion#code) |
| 2023     | [VideoFusion: Decomposed Diffusion Models for High-Quality Video Generation](https://paperswithcode.com/paper/decomposed-diffusion-models-for-high-quality) | CVPR      | [link](https://paperswithcode.com/paper/decomposed-diffusion-models-for-high-quality#code) |
| 20230323 | [Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators](https://paperswithcode.com/paper/text2video-zero-text-to-image-diffusion) | arxiv     | [link](https://paperswithcode.com/paper/text2video-zero-text-to-image-diffusion#code) |
| 20230522 | [VDT: An Empirical Study on Video Diffusion with Transformers](https://paperswithcode.com/paper/vdt-an-empirical-study-on-video-diffusion) | arxiv     | [link](https://paperswithcode.com/paper/vdt-an-empirical-study-on-video-diffusion#code) |
| 20220615 | [Diffusion Models for Video Prediction and Infilling](https://paperswithcode.com/paper/diffusion-models-for-video-prediction-and) | arxiv     | [link](https://paperswithcode.com/paper/diffusion-models-for-video-prediction-and#code) |
| 20221123 | [Unsupervised Learning for Physical Interaction through Video Prediction](https://paperswithcode.com/paper/unsupervised-learning-for-physical) | arxiv     | [link](https://paperswithcode.com/paper/unsupervised-learning-for-physical#code) |
| 2023     | [DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image) | CVPR      | [link](https://paperswithcode.com/paper/dreambooth-fine-tuning-text-to-image#code) |
| 2023     | [ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts](https://paperswithcode.com/paper/ernie-vilg-2-0-improving-text-to-image) | CVPR      | [link](https://paperswithcode.com/paper/ernie-vilg-2-0-improving-text-to-image#code) |
| 20230512 | [One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale](https://paperswithcode.com/paper/one-transformer-fits-all-distributions-in) | arxiv     | [link]()                                                     |
| 2023     | [DreamFusion: Text-to-3D using 2D Diffusion]([[2209.14988\] DreamFusion: Text-to-3D using 2D Diffusion (arxiv.org)](https://arxiv.org/abs/2209.14988)) | ICLR oral | [link](https://github.com/ashawkey/stable-dreamfusion)       |
| 20221120 | [Auto Regressive latent diffusion model]([arxiv.org/abs/2211.10950](https://arxiv.org/abs/2211.10950)) | arxiv     | [link]([Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models](https://paperswithcode.com/paper/synthesizing-coherent-story-with-auto)) |
| 20230531 | [Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D Diffusion-based Editor]([[2305.20082\] Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D Diffusion-based Editor (arxiv.org)](https://arxiv.org/abs/2305.20082)) | arxiv     | [link](https://arxiv.org/abs/2305.20082)                     |
| 20230413 | [RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment]([[2304.06767\] RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment (arxiv.org)](https://arxiv.org/abs/2304.06767#:~:text=To this end%2C we introduce a new framework%2C,undesired behavior%2C and subsequently assembles a streaming dataset.)) | arxiv     | [link]()                                                     |
| 20230419 | [Anything-3D: Towards Single-view Anything Reconstruction in the Wild](https://paperswithcode.com/paper/anything-3d-towards-single-view-anything) | arxiv     | [link]()                                                     |



### Conditional generation

this part include text2image, few-shot , one-short and other researches about conditional generation. Generating images and videos under certain type of instructions has a prosperous future in commercial and daily uses. At the same time , this can be very difficult to satisfy peopleâ€™s expectations. 

| Time     | Title                                                        | Venue | Code                                                         |
| -------- | ------------------------------------------------------------ | ----- | ------------------------------------------------------------ |
| 2022128  | [Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models](https://paperswithcode.com/paper/refining-generative-process-with) | arxiv | [link](https://paperswithcode.com/paper/refining-generative-process-with#code) |
| 20210112 | [D2C: Diffusion-Denoising Models for Few-shot Conditional Generation](https://paperswithcode.com/paper/d2c-diffusion-denoising-models-for-few-shot) | arxiv | [link](https://paperswithcode.com/paper/d2c-diffusion-denoising-models-for-few-shot#code) |
| 20220623 | [Entropy-driven Sampling and Training Scheme for Conditional Diffusion Generation](https://paperswithcode.com/paper/entropy-driven-sampling-and-training-scheme) | arxiv | [link](https://paperswithcode.com/paper/entropy-driven-sampling-and-training-scheme#code) |
| 20220829 | [Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis](https://paperswithcode.com/paper/frido-feature-pyramid-diffusion-for-complex) | arxiv | [link](https://paperswithcode.com/paper/frido-feature-pyramid-diffusion-for-complex#code) |
| 20230221 | [Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels](https://paperswithcode.com/paper/diffusion-models-and-semi-supervised-learners) | arxiv | [link](https://paperswithcode.com/paper/diffusion-models-and-semi-supervised-learners#code) |
| 20211126 | [Conditional Image Generation with Score-Based Diffusion Models](https://paperswithcode.com/paper/conditional-image-generation-with-score-based) | arxiv | [link](https://paperswithcode.com/paper/conditional-image-generation-with-score-based#code) |
| 20230519 | [Late-Constraint Diffusion Guidance for Controllable Image Synthesis](https://paperswithcode.com/paper/late-constraint-diffusion-guidance-for) | arxiv | [link](https://paperswithcode.com/paper/late-constraint-diffusion-guidance-for#code) |
| 20230503 | [Shap-E: Generating Conditional 3D Implicit Functions](https://arxiv.org/abs/2305.02463)-**openai** | arxiv | [link]([openai/shap-e: Generate 3D objects conditioned on text or images (github.com)](https://github.com/openai/shap-e)) |



### Theory and Engineering improvement 

In fact, while diffusion models have a higher performance upbound, the training and inferring cost can be high. So it would be very interesting and meaningful to research about reducing unnecessary cost of diffusion-based models. 

One of the most famous paper that fit this part is [DDPM](https://paperswithcode.com/paper/denoising-diffusion-implicit-models-1),which made application possible for diffusion models, but it is to old and famous too be presented in this chart.  

| Time     | Title                                                        | Venue | Code                                                         |
| -------- | ------------------------------------------------------------ | ----- | ------------------------------------------------------------ |
| 20220101 | [Elucidating the Design Space of Diffusion-Based Generative Models](https://paperswithcode.com/paper/elucidating-the-design-space-of-diffusion) | arxiv | [link](https://paperswithcode.com/paper/singan-learning-a-generative-model-from-a#code) |
| 20210218 | [Improved Denoising Diffusion Probabilistic Models](https://paperswithcode.com/paper/improved-denoising-diffusion-probabilistic-1)-**openai** | arxiv | [link](https://paperswithcode.com/paper/improved-denoising-diffusion-probabilistic-1#code) |
| 2022     | [Vector Quantized Diffusion Model for Text-to-Image Synthesis](https://paperswithcode.com/paper/vector-quantized-diffusion-model-for-text-to) | CVPR  | [link](https://paperswithcode.com/paper/vector-quantized-diffusion-model-for-text-to#code) |



### dataset

some new dataset for diffusion models. 

| dataset                                                      | paper                                      | github                                                       |
| ------------------------------------------------------------ | ------------------------------------------ | ------------------------------------------------------------ |
| **Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation** | [link](https://github.com/lisadunlap/ALIA) | [link](https://github.com/lisadunlap/ALIA)                   |
| **DiffuseExpand: Expanding dataset for 2D medical image segmentation using diffusion models** | [link](https://arxiv.org/abs/2304.13416)   | [link](https://anonymous.4open.science/r/DiffuseExpand/README.md) |
| **Realistic Data Enrichment for Robust Image Segmentation in Histopathology** | [link](https://arxiv.org/abs/2304.09534)   | /                                                            |
| **A Multi-Institutional Open-Source Benchmark Dataset for Breast Cancer Clinical Decision Support using Synthetic Correlated Diffusion Imaging Data** | [link](https://arxiv.org/abs/2304.05623)   |                                                              |
| **Diffusion-based Data Augmentation for Skin Disease Classification: Impact Across Original Medical Datasets to Fully Synthetic Images** | [link](https://arxiv.org/abs/2301.04802)   |                                                              |
| **Diversify Your Vision Datasets with Automatic Diffusion-Based Augmentation** | [link](https://arxiv.org/abs/2305.16289)   | [link](https://github.com/lisadunlap/ALIA)                   |

